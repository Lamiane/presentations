{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple examples for warming up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "synthetic(?) XOR data, RBF kernels, svm.NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(-3, 3, 500),\n",
    "                     np.linspace(-3, 3, 500))\n",
    "np.random.seed(0)\n",
    "X = np.random.randn(300, 2)\n",
    "Y = np.logical_xor(X[:, 0] > 0, X[:, 1] > 0)\n",
    "\n",
    "# fit the model\n",
    "clf = svm.NuSVC()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "# plot the decision function for each datapoint on the grid\n",
    "Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()), aspect='auto',\n",
    "           origin='lower', cmap=plt.cm.PuOr_r)\n",
    "contours = plt.contour(xx, yy, Z, levels=[0], linewidths=2,\n",
    "                       linetypes='--')\n",
    "plt.scatter(X[:, 0], X[:, 1], s=30, c=Y, cmap=plt.cm.Paired)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.axis([-3, 3, -3, 3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "###############################################################################\n",
    "# Generate sample data\n",
    "X = np.sort(5 * np.random.rand(40, 1), axis=0)\n",
    "y = np.sin(X).ravel()\n",
    "\n",
    "###############################################################################\n",
    "# Add noise to targets\n",
    "y[::5] += 3 * (0.5 - np.random.rand(8))\n",
    "\n",
    "###############################################################################\n",
    "# Fit regression model\n",
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr_lin = SVR(kernel='linear', C=1e3)\n",
    "svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "y_rbf = svr_rbf.fit(X, y).predict(X)\n",
    "y_lin = svr_lin.fit(X, y).predict(X)\n",
    "y_poly = svr_poly.fit(X, y).predict(X)\n",
    "\n",
    "###############################################################################\n",
    "# look at the results\n",
    "plt.scatter(X, y, c='k', label='data')\n",
    "plt.hold('on')\n",
    "plt.plot(X, y_rbf, c='g', label='RBF model')\n",
    "plt.plot(X, y_lin, c='r', label='Linear model')\n",
    "plt.plot(X, y_poly, c='b', label='Polynomial model')\n",
    "plt.xlabel('data')\n",
    "plt.ylabel('target')\n",
    "plt.title('Support Vector Regression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maximum margin separating the hyperplane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X and y have incompatible shapes.\nX has 420 samples, but y has 40.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2d40d953f746>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# get the separating hyperplane\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/nex/Libraries/anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    149\u001b[0m             raise ValueError(\"X and y have incompatible shapes.\\n\" +\n\u001b[0;32m    150\u001b[0m                              \u001b[1;34m\"X has %s samples, but y has %s.\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m                              (X.shape[0], y.shape[0]))\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"precomputed\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X and y have incompatible shapes.\nX has 420 samples, but y has 40."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "\n",
    "# we create 40 separable points\n",
    "np.random.seed(30)\n",
    "X = np.r_[np.random.randn(20, 2) - [2, 2], np.random.randn(20, 2) + [2, 2]]\n",
    "Y = [0] * 20 + [1] * 20\n",
    "\n",
    "# fit the model\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X, Y)\n",
    "\n",
    "# get the separating hyperplane\n",
    "w = clf.coef_[0]\n",
    "a = -w[0] / w[1]\n",
    "xx = np.linspace(-5, 5)\n",
    "yy = a * xx - (clf.intercept_[0]) / w[1]\n",
    "\n",
    "# plot the parallels to the separating hyperplane that pass through the\n",
    "# support vectors\n",
    "b = clf.support_vectors_[0]\n",
    "yy_down = a * xx + (b[1] - a * b[0])\n",
    "b = clf.support_vectors_[-1]\n",
    "yy_up = a * xx + (b[1] - a * b[0])\n",
    "\n",
    "# plot the line, the points, and the nearest vectors to the plane\n",
    "plt.plot(xx, yy, 'k-')\n",
    "plt.plot(xx, yy_down, 'k--')\n",
    "plt.plot(xx, yy_up, 'k--')\n",
    "\n",
    "plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1],\n",
    "            s=80, facecolors='none')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Paired)\n",
    "\n",
    "plt.axis('tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "separating hyperplane for unbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# we create 40 separable points\n",
    "rng = np.random.RandomState(0)\n",
    "n_samples_1 = 1000\n",
    "n_samples_2 = 100\n",
    "X = np.r_[1.5 * rng.randn(n_samples_1, 2),\n",
    "          0.5 * rng.randn(n_samples_2, 2) + [2, 2]]\n",
    "y = [0] * (n_samples_1) + [1] * (n_samples_2)\n",
    "\n",
    "# fit the model and get the separating hyperplane\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X, y)\n",
    "\n",
    "w = clf.coef_[0]\n",
    "a = -w[0] / w[1]\n",
    "xx = np.linspace(-5, 5)\n",
    "yy = a * xx - clf.intercept_[0] / w[1]\n",
    "\n",
    "\n",
    "# get the separating hyperplane using weighted classes\n",
    "wclf = svm.SVC(kernel='linear', class_weight={1: 10})\n",
    "wclf.fit(X, y)\n",
    "\n",
    "ww = wclf.coef_[0]\n",
    "wa = -ww[0] / ww[1]\n",
    "wyy = wa * xx - wclf.intercept_[0] / ww[1]\n",
    "\n",
    "# plot separating hyperplanes and samples\n",
    "h0 = plt.plot(xx, yy, 'k-', label='no weights')\n",
    "h1 = plt.plot(xx, wyy, 'k--', label='with weights')\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "plt.legend()\n",
    "\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "svm with custom kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features. We could\n",
    "                      # avoid this ugly slicing by using a two-dim dataset\n",
    "Y = iris.target\n",
    "\n",
    "\n",
    "def my_kernel(X, Y):\n",
    "    \"\"\"\n",
    "    We create a custom kernel:\n",
    "\n",
    "                 (2  0)\n",
    "    k(X, Y) = X  (    ) Y.T\n",
    "                 (0  1)\n",
    "    \"\"\"\n",
    "    M = np.array([[2, 0], [0, 1.0]])\n",
    "    return np.dot(np.dot(X, M), Y.T)\n",
    "\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# we create an instance of SVM and fit out data.\n",
    "clf = svm.SVC(kernel=my_kernel)\n",
    "clf.fit(X, Y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Paired)\n",
    "plt.title('3-Class classification using Support Vector Machine with custom'\n",
    "          ' kernel')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "weighted samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "def plot_decision_function(classifier, sample_weight, axis, title):\n",
    "    # plot the decision function\n",
    "    xx, yy = np.meshgrid(np.linspace(-4, 5, 500), np.linspace(-4, 5, 500))\n",
    "\n",
    "    Z = classifier.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # plot the line, the points, and the nearest vectors to the plane\n",
    "    axis.contourf(xx, yy, Z, alpha=0.75, cmap=plt.cm.bone)\n",
    "    axis.scatter(X[:, 0], X[:, 1], c=Y, s=100 * sample_weight, alpha=0.9,\n",
    "                 cmap=plt.cm.bone)\n",
    "\n",
    "    axis.axis('off')\n",
    "    axis.set_title(title)\n",
    "\n",
    "\n",
    "# we create 20 points\n",
    "np.random.seed(0)\n",
    "X = np.r_[np.random.randn(10, 2) + [1, 1], np.random.randn(10, 2)]\n",
    "Y = [1] * 10 + [-1] * 10\n",
    "sample_weight_last_ten = abs(np.random.randn(len(X)))\n",
    "sample_weight_constant = np.ones(len(X))\n",
    "# and bigger weights to some outliers\n",
    "sample_weight_last_ten[15:] *= 5\n",
    "sample_weight_last_ten[9] *= 15\n",
    "\n",
    "# for reference, first fit without class weights\n",
    "\n",
    "# fit the model\n",
    "clf_weights = svm.SVC()\n",
    "clf_weights.fit(X, Y, sample_weight=sample_weight_last_ten)\n",
    "\n",
    "clf_no_weights = svm.SVC()\n",
    "clf_no_weights.fit(X, Y)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "plot_decision_function(clf_no_weights, sample_weight_constant, axes[0],\n",
    "                       \"Constant weights\")\n",
    "plot_decision_function(clf_weights, sample_weight_last_ten, axes[1],\n",
    "                       \"Modified weights\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "novelty detectoion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "from sklearn import svm\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(-5, 5, 500), np.linspace(-5, 5, 500))\n",
    "# Generate train data\n",
    "X = 0.3 * np.random.randn(100, 2)\n",
    "X_train = np.r_[X + 2, X - 2]\n",
    "# Generate some regular novel observations\n",
    "X = 0.3 * np.random.randn(20, 2)\n",
    "X_test = np.r_[X + 2, X - 2]\n",
    "# Generate some abnormal novel observations\n",
    "X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))\n",
    "\n",
    "# fit the model\n",
    "clf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n",
    "clf.fit(X_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_pred_outliers = clf.predict(X_outliers)\n",
    "n_error_train = y_pred_train[y_pred_train == -1].size\n",
    "n_error_test = y_pred_test[y_pred_test == -1].size\n",
    "n_error_outliers = y_pred_outliers[y_pred_outliers == 1].size\n",
    "\n",
    "# plot the line, the points, and the nearest vectors to the plane\n",
    "Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.title(\"Novelty Detection\")\n",
    "plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 7), cmap=plt.cm.Blues_r)\n",
    "a = plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='red')\n",
    "plt.contourf(xx, yy, Z, levels=[0, Z.max()], colors='orange')\n",
    "\n",
    "b1 = plt.scatter(X_train[:, 0], X_train[:, 1], c='white')\n",
    "b2 = plt.scatter(X_test[:, 0], X_test[:, 1], c='green')\n",
    "c = plt.scatter(X_outliers[:, 0], X_outliers[:, 1], c='red')\n",
    "plt.axis('tight')\n",
    "plt.xlim((-5, 5))\n",
    "plt.ylim((-5, 5))\n",
    "plt.legend([a.collections[0], b1, b2, c],\n",
    "           [\"learned frontier\", \"training observations\",\n",
    "            \"new regular observations\", \"new abnormal observations\"],\n",
    "           loc=\"upper left\",\n",
    "           prop=matplotlib.font_manager.FontProperties(size=11))\n",
    "plt.xlabel(\n",
    "    \"error train: %d/200 ; errors novel regular: %d/40 ; \"\n",
    "    \"errors novel abnormal: %d/40\"\n",
    "    % (n_error_train, n_error_test, n_error_outliers))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernels comparision i do tego jeszcze multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features. We could\n",
    "                      # avoid this ugly slicing by using a two-dim dataset\n",
    "y = iris.target\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# we create an instance of SVM and fit out data. We do not scale our\n",
    "# data since we want to plot the support vectors\n",
    "C = 1.0  # SVM regularization parameter\n",
    "svc = svm.SVC(kernel='linear', C=C).fit(X, y)\n",
    "rbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=C).fit(X, y)\n",
    "poly_svc = svm.SVC(kernel='poly', degree=3, C=C).fit(X, y)\n",
    "lin_svc = svm.LinearSVC(C=C).fit(X, y)\n",
    "\n",
    "# create a mesh to plot in\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# title for the plots\n",
    "titles = ['SVC with linear kernel',\n",
    "          'LinearSVC (linear kernel)',\n",
    "          'SVC with RBF kernel',\n",
    "          'SVC with polynomial (degree 3) kernel']\n",
    "\n",
    "\n",
    "for i, clf in enumerate((svc, lin_svc, rbf_svc, poly_svc)):\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "    plt.xlabel('Sepal length')\n",
    "    plt.ylabel('Sepal width')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(titles[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-5c3978140b30>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-5c3978140b30>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    kernels such beautiful example, binary data\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "kernels such beautiful example, binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "# Our dataset and targets\n",
    "X = np.c_[(.4, -.7),\n",
    "          (-1.5, -1),\n",
    "          (-1.4, -.9),\n",
    "          (-1.3, -1.2),\n",
    "          (-1.1, -.2),\n",
    "          (-1.2, -.4),\n",
    "          (-.5, 1.2),\n",
    "          (-1.5, 2.1),\n",
    "          (1, 1),\n",
    "          # --\n",
    "          (1.3, .8),\n",
    "          (1.2, .5),\n",
    "          (.2, -2),\n",
    "          (.5, -2.4),\n",
    "          (.2, -2.3),\n",
    "          (0, -2.7),\n",
    "          (1.3, 2.1)].T\n",
    "Y = [0] * 8 + [1] * 8\n",
    "\n",
    "# figure number\n",
    "fignum = 1\n",
    "\n",
    "# fit the model\n",
    "for kernel in ('linear', 'poly', 'rbf'):\n",
    "    clf = svm.SVC(kernel=kernel, gamma=2)\n",
    "    clf.fit(X, Y)\n",
    "\n",
    "    # plot the line, the points, and the nearest vectors to the plane\n",
    "    plt.figure(fignum, figsize=(4, 3))\n",
    "    plt.clf()\n",
    "\n",
    "    plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=80,\n",
    "                facecolors='none', zorder=10)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y, zorder=10, cmap=plt.cm.Paired)\n",
    "\n",
    "    plt.axis('tight')\n",
    "    x_min = -3\n",
    "    x_max = 3\n",
    "    y_min = -3\n",
    "    y_max = 3\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.figure(fignum, figsize=(4, 3))\n",
    "    plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'],\n",
    "                levels=[-.5, 0, .5])\n",
    "\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    fignum = fignum + 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
